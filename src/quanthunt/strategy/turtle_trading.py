import logging
import os

import numpy as np
import pandas as pd
import statistics
from sklearn.preprocessing import StandardScaler
from hmmlearn.hmm import GaussianHMM
from quanthunt.strategy.algo_util.hmm_selector import HMMTrendSelector
from quanthunt.strategy.algo_util.bocpd import apply_bocpd_to_df
from quanthunt.strategy.algo_util.performance import (
    compare_signal_filters,
    analyze_hmm_states,
)
from quanthunt.strategy.algo_util.kalman import (
    init_mosaic_state,
    mosaic_step,
    build_kalman_params,
    prepare_mosaic_input,
    MosaicForceAdapter,
    MosaicPriceAdapter,
    CycleStateAdapter,
)
from quanthunt.strategy.algo_util.bocpdz import (
    BOCPDGaussianG0,
    BOCPDStudentTP1,
    DualBOCPD,
    PhaseFSMConfig,
    BOCPDPhaseFSM,
    DualBOCPDWrapper,
)
from quanthunt.hunterverse.interface import IStrategyScout, ZERO
from quanthunt.utils import pandas_util

logger = logging.getLogger(__name__)

# FIXME: move some columns to IEngine
TURTLE_COLUMNS = [
    "TR",
    "ATR",
    "turtle_h",
    "turtle_l",
    "Stop_profit",
    "exit_price",
    "OBV_UP",
    "VWMA",
    "buy",
    "sell",
    "profit",
    "time_cost",
    "Matured",
    "BuySignal",
    "P/L",
    "PRICE_VOL_reduce",
    "Rolling_Std",
    "ema_short",
    "ema_long",
    "+DM",
    "-DM",
    "ADX",
    "ADX_Signed",
    "drift",
    "volatility",
    "pred_price",
    "Kalman",
    "log_returns",
    "global_log_volatility",
    "global_log_vol",
    "KReturn",
    "KReturnVol",
    "RVolume",
    "HMM_State",
    "UP_State",
    "HMM_Signal",
    "adjusted_margin",
    "Count_Hz",
    "close_sortino",
    "vol_sortino",
    "trend",
    "cv",
    "cv_sum",
    "RCS",
    "trend_norm",
    "TR_norm",
    "bias_off_norm",
    # MOSAIC model
    "force_proxy",
    "m_pc",
    "m_pt_speed",
    "m_pt_accel",
    "m_force",
    "m_force_trend",
    "m_force_bias",
    "m_z_price",
    "m_z_force",
    "m_z_mix",
    "m_regime_noise_level",
    "c_center",
    "c_z_center",
    # BOCPD G0+P1
    "bocpd_phase",
    "bocpd_cp_prob",
    "bocpd_runlen_mean",
    "bocpd_runlen_mode",
    "bocpd_risk",
    "bocpd_tail",
    "bocpd_shock",
]


class TurtleScout(IStrategyScout):
    def __init__(self, params, buy_signal_func=None):
        self.params = params
        ATR_sample = self.params.ATR_sample
        upper_sample = self.params.upper_sample
        lower_sample = self.params.lower_sample
        self.window = max(ATR_sample, upper_sample, lower_sample) * 2
        # Set the buy_signal_func, default to the simple_turtle_strategy if none is provided
        self.buy_signal_func = buy_signal_func or self._simple_turtle_strategy

        self.trend_scaler = StandardScaler()
        self.trend_hmm_model = GaussianHMM(
            n_components=self.params.hmm_split,
            covariance_type="full",
            n_iter=4000,
            random_state=42,
        )

        self.cycle_scaler = StandardScaler()
        self.cycle_hmm_model = GaussianHMM(
            n_components=self.params.hmm_split,
            covariance_type="full",
            n_iter=4000,
            random_state=42,
        )

        self.bocpd_wrapper = None
        self.kalman_state = None
        self.kalman_Cov = None
        self.m_params = None
        self.m_regime_params = None

        self.m_force_model = None
        self.m_price_model = None
        self.m_cycle_model = None

    def train(self, df):
        df = pandas_util.equip_fields(df, TURTLE_COLUMNS)
        buy_signal_from_mosaic_strategy(df, self.params)
        df = self._calc_ATR(df)
        df = self._calc_OBV(df)
        df = self.calc_kalman(df)
        df = self.train_hmm(df)
        df = self._calc_profit(df)
        return df

    def calc_kalman(self, df):
        df = prepare_mosaic_input(df)

        # Initiallize Mosaic/Cycle Kalman filter
        start_idx = df.index[df["m_pc"].isna()][0]
        if not (self.kalman_state and self.kalman_Cov):
            self.kalman_state, self.kalman_Cov = init_mosaic_state(
                init_pc=df.loc[start_idx, "Close"]
            )
            self.m_params, self.m_regime_params = build_kalman_params()
            self.m_force_model = MosaicForceAdapter(self.m_params["force"])
            self.m_price_model = MosaicPriceAdapter(self.m_params["price"])
            self.m_cycle_model = CycleStateAdapter(self.m_params["cycle"])

        for i in range(start_idx, len(df)):
            if not pd.isna(df.loc[i, "m_pc"]):
                continue

            obs_close = float(df.loc[i, "Close"])
            obs_force = float(df.loc[i, "force_proxy"])

            self.kalman_state, self.kalman_Cov, diag = mosaic_step(
                state=self.kalman_state,
                cov=self.kalman_Cov,
                obs_close=obs_close,
                obs_force=obs_force,
                force_model=self.m_force_model,
                price_model=self.m_price_model,
                cycle_model=self.m_cycle_model,
                regime_params=self.m_regime_params,
            )

            # === write back ===
            df.loc[i, "Kalman"] = np.exp(self.kalman_state["pc"])
            df.loc[i, "m_pc"] = np.exp(self.kalman_state["pc"])
            df.loc[i, "m_pt_speed"] = self.kalman_state["pt_speed"]
            df.loc[i, "m_pt_accel"] = self.kalman_state["pt_accel"]

            df.loc[i, "m_force"] = self.kalman_state["force_imbalance"]
            df.loc[i, "m_force_trend"] = self.kalman_state["force_imbalance_trend"]
            df.loc[i, "m_force_bias"] = self.kalman_state["force_proxy_bias"]

            df.loc[i, "m_z_price"] = diag["z_price"]
            df.loc[i, "m_z_force"] = diag["z_force"]
            df.loc[i, "m_z_mix"] = diag["z_mix"]
            df.loc[i, "m_regime_noise_level"] = self.kalman_state["regime_noise_level"]

            df.loc[i, "c_center"] = self.kalman_state["cycle_center"]
            df.loc[i, "c_z_center"] = diag["z_cycle"]

        return df

    def define_market_states(self, df: pd.DataFrame) -> pd.DataFrame:
        up_state = hmm_performance(df)

        s = df["UP_State"].isna()
        df.loc[s, "UP_State"] = up_state

        s = df["HMM_Signal"].isna()
        df.loc[s, "HMM_Signal"] = (
            df.loc[s, "HMM_State"] == df.loc[s, "UP_State"]
        ).astype(int)

        return df

    def train_hmm(self, df: pd.DataFrame) -> pd.DataFrame:
        X = self._prepare_trend_hmm_features(df)
        self.trend_scaler.fit(X)
        X = self.trend_scaler.transform(X)
        self.trend_hmm_model.fit(X)
        trend_hidden_states = self.trend_hmm_model.predict(X)

        Y = self._prepare_cycle_hmm_features(df)
        self.cycle_scaler.fit(Y)
        Y = self.cycle_scaler.transform(Y)
        self.cycle_hmm_model.fit(Y)
        cycle_hidden_states = self.cycle_hmm_model.predict(Y)

        # mask = df["HMM_State"].isna()
        # df.loc[mask, "HMM_State"] = trend_hidden_states[mask]

        mask = df["HMM_State"].isna()
        df.loc[mask, "HMM_State"] = cycle_hidden_states[mask]
        # df = self.define_market_states(df)
        df = self.predict_market_states(df)
        return df

    def _prepare_cycle_hmm_features(self, df: pd.DataFrame) -> np.ndarray:
        """
        CycleHMM feature set
        - å°ˆæ³¨æ–¼åé›¢ã€å›æ­¸å‹•åŠ›ã€çµæ§‹ç©©å®šåº¦
        """

        # --- åé›¢ç¨‹åº¦ ---
        df["gap"] = df["Close"] - df["c_center"]
        df["gap_norm"] = df["gap"] / df["c_z_center"].abs()

        # --- åé›¢å‹•åŠ›å­¸ ---
        df["gap_speed"] = df["m_pc"]
        df["gap_accel"] = df["m_pt_accel"]

        # --- çµæ§‹ / regime ---
        df["z_center"] = df["c_z_center"]
        df["regime_noise"] = df["m_regime_noise_level"]
        df["z_mix"] = df["m_z_mix"]

        features = [
            "gap_norm",
            "gap_speed",
            "gap_accel",
            "z_center",
            "regime_noise",
            "z_mix",
        ]

        df[features] = df[features].fillna(method="bfill").fillna(method="ffill")
        return df[features].values

    def _prepare_trend_hmm_features(self, df: pd.DataFrame) -> np.ndarray:
        """
        HMM ç‰¹å¾µå·¥ç¨‹ï¼ˆV4 è¡Œç‚º + çµæ§‹ + è¶¨å‹¢æ–¹å‘ç‰ˆï¼‰

        çµæ§‹é¡ï¼š
            - trend_norm      : è¶¨å‹¢å¼·å¼±ï¼ˆKalman - EMA_longï¼‰/ ATR
            - TR_norm         : æ³¢å‹•å¼·å¼±ï¼ˆATR / ATRå‡å€¼ï¼‰çš„ log æ¯”
            - slope_norm      : Kalman æ–œç‡ / ATRï¼ˆçœŸæ­£çš„è¶¨å‹¢æ–¹å‘ï¼‰

        è¡Œç‚ºé¡ï¼š
            - RCS             : Resonance Consensus Strengthï¼ˆå…±è­˜å¼·åº¦ï¼‰
            - dd_proxy        : åƒ¹æ ¼è‡ªèº«æ¨å¾—çš„å±€éƒ¨å›æ’¤æ¯”ä¾‹
        """

        ATR_sample = self.params.ATR_sample
        ZERO = 1e-9

        # ========== è¡Œç‚ºå› å­ï¼ˆRCSï¼‰ ==========
        _momentum_factor = (df.High - df.Close) / (df.TR + ZERO)
        _res_strength = df.TR * df.Vol * _momentum_factor

        _consensus_strength = (df.Kalman / df.Close).clip(0.1, 10) * df.Vol
        _consensus_norm = (
            _consensus_strength / _consensus_strength.rolling(window=ATR_sample).mean()
        )

        df["RCS"] = _res_strength * _consensus_norm

        # ========== çµæ§‹å› å­ ==========
        # è¶¨å‹¢å¼·å¼±ï¼ˆKalman - EMA_longï¼‰
        df["trend"] = df.Kalman - df["ema_long"]
        df["trend_norm"] = df.trend / (df.ATR + ZERO)

        # æ³¢å‹•å¼·å¼±ï¼ˆATR ç›¸å°æ–¼è‡ªèº«æ­·å²å‡å€¼ï¼‰
        df["TR_norm"] = np.log(
            df.ATR + ZERO / (df.ATR.rolling(window=ATR_sample).mean() + ZERO)
        )

        # **æ–°å¢ï¼šè¶¨å‹¢æ–¹å‘ï¼ˆKalman æ–œç‡ï¼‰**
        df["slope_norm"] = df.m_pt_speed.diff() / (df.ATR + ZERO)

        # ========== æ–°å¢ï¼šè¶¨å‹¢æŒçºŒæ€§ / åæ…‹ / å›æ’¤ Proxy ==========
        # 3) å±€éƒ¨ Drawdown proxy
        roll_max = df["Close"].cummax()
        df["dd_proxy"] = (roll_max - df["Close"]) / (roll_max + ZERO)

        # --- Final features ---
        features = [
            "trend_norm",
            "slope_norm",
            "RCS",
            "TR_norm",
            "dd_proxy",
        ]

        df[features] = df[features].fillna(method="bfill").fillna(method="ffill")
        return df[features].values

    def predict_market_states(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ¹æ“š HMMTrendSelector é¸å‡ºã€Œæœ€å€¼å¾—åšå¤šçš„ HMM_Stateã€
        ä¸¦å¡«å…¥ï¼š
            - UP_State  : å…¨å±€æ¨è–¦çš„ä¸Šå‡ç‹€æ…‹ï¼ˆå–®ä¸€ state idï¼‰
            - HMM_Signal: ç•¶å‰ row çš„ HMM_State == UP_State æ™‚ï¼Œçµ¦ 1ï¼Œå¦å‰‡ 0
        """

        # ç¢ºä¿ profit æ¬„ä½å­˜åœ¨ï¼ˆé€™è£¡å‡è¨­ä½ å›æ¸¬å·²ç¶“ç®—å¥½ï¼‰
        if "profit" not in df.columns:
            raise ValueError(
                "define_market_states éœ€è¦ df å…§å« 'profit' æ¬„ä½ï¼Œè«‹å…ˆå›å¡«ç­–ç•¥ç›ˆè™§ã€‚"
            )

        # 1) ç”¨ Trend Î¼ æŒ‘å‡ºæœ€å¼·çš„å–®ä¸€ state
        selector = HMMTrendSelector(
            df,
            state_col="HMM_State",
            profit_col="profit",
            min_samples=500,  # å¯æ”¹æˆ self.params.min_hmm_samples ä¹‹é¡
        )
        best_states = selector.best_states(top_n=1)
        best_combo = selector.best_combos(top_n=1)
        combo_states = set(best_combo.iloc[0]["combo"])
        print(selector.best_combos(top_n=1))
        if best_states.empty or best_states["trend_mu"].iloc[0] <= 0:
            # æ‰¾ä¸åˆ°æœ‰æ­£æœŸæœ›çš„ stateï¼Œå°±ä¸è¦äº‚æ‰“ HMM_Signal
            return df

        up_state = int(best_states["state"].iloc[0])

        # 2) åªå¡«å°šæœªè¨­å®šçš„ UP_State
        s = df["UP_State"].isna()
        df.loc[s, "UP_State"] = up_state

        # 3) HMM_Signalï¼šç•¶å‰ HMM_State == UP_State æ™‚æ¨™è¨˜ 1
        s = df["HMM_Signal"].isna()
        # Single HMM State
        # df.loc[s, "HMM_Signal"] = (
        #     df.loc[s, "HMM_State"] == df.loc[s, "UP_State"]
        # ).astype(int)
        # Combo HMM State
        df.loc[s, "HMM_Signal"] = df.loc[s, "HMM_State"].isin(combo_states).astype(int)
        return df

    def predict_hmm(self, df: pd.DataFrame) -> pd.DataFrame:
        X = self._prepare_trend_hmm_features(df)
        X = self.trend_scaler.transform(X)
        trend_hidden_states = self.trend_hmm_model.predict(X)

        Y = self._prepare_cycle_hmm_features(df)
        Y = self.cycle_scaler.transform(Y)
        cycle_hidden_states = self.cycle_hmm_model.predict(Y)

        # mask = df["HMM_State"].isna()
        # df.loc[mask, "HMM_State"] = trend_hidden_states[mask]

        mask = df["HMM_State"].isna()
        df.loc[mask, "HMM_State"] = cycle_hidden_states[mask]

        # df = self.define_market_states(df)
        df = self.predict_market_states(df)
        return df

    def adjust_exit_price_by_slope(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ã€åŠ¨æ€æ­¢æŸã€‘ã€è¶‹åŠ¿å¼ºå¼±ã€‘ã€Kalmanã€‘ã€Slopeã€‘ã€HMMã€‘
        æ ¹æ®è¶‹åŠ¿å¼ºå¼±åŠ¨æ€è°ƒæ•´ ATR å¹³ä»“é—¨æ§›ï¼Œå¹¶è®¡ç®— exit_priceã€‚

        - ä½¿ç”¨å·²å­˜åœ¨çš„ Slope æŒ‡æ ‡ï¼ˆæ¥è‡ª Kalman ä¸ local_lowï¼‰
        - è¶‹åŠ¿å¼ºï¼ˆHMM_State == UP_Stateï¼‰ï¼šä½¿ç”¨æœ€å¤§ ATR å€æ•°
        - è¶‹åŠ¿å¼±ï¼šåœ¨ atr_margin_min ~ atr_margin_max é—´æ’å€¼
        - è‡ªåŠ¨ clip Slope å€¼ï¼Œé¿å…æç«¯å€¼å¤±æ§
        - è¾“å‡ºæ›´æ–°åçš„ dfï¼ŒåŒ…å« adjusted_margin ä¸ exit_price
        """

        # ===ã€å‚æ•°è½½å…¥ã€‘===
        hmm_signal = df.iloc[-1].HMM_Signal  # å…³é”®å­—ï¼šHMMã€ä¸Šå‡è¶‹åŠ¿çŠ¶æ€
        slope_col = "m_pt_speed"
        atr_margin_max = self.params.atr_loss_margin
        atr_margin_min = getattr(self.params, "atr_margin_min", 0.1)

        # ===ã€è¶‹åŠ¿å¼ºå¼±ã€‘Slope å·²é¢„å…ˆå­˜åœ¨ï¼Œé¿å…é‡å¤è®¡ç®—===
        slope = df[slope_col]

        # ===ã€clipï¼šé™åˆ¶æ–œç‡èŒƒå›´ï¼Œé¿å…å¼‚å¸¸æ³¢åŠ¨ã€‘===
        slope_clip_min = slope.quantile(0.05)  # è¶‹åŠ¿æœ€å¼±
        slope_clip_max = slope.quantile(0.50)  # å¹³ç¨³è¶‹åŠ¿æˆ–å¾®å‡

        slope_clipped = slope.clip(slope_clip_min, slope_clip_max)

        # ===ã€normalizedï¼šæ˜ å°„åˆ°0~1ä¹‹é—´ï¼Œç”¨æ¥æ’å€¼ã€‘===
        normalized = (slope_clipped - slope_clip_min) / (
            slope_clip_max - slope_clip_min
        )

        # ===ã€åŠ¨æ€æ­¢æŸé—¨æ§›ï¼šè¶‹åŠ¿è¶Šå¼± â†’ margin è¶Šå° â†’ è¶Šå®¹æ˜“é€€å‡ºã€‘===
        dynamic_margin = atr_margin_min + (atr_margin_max - atr_margin_min) * normalized

        # ===ã€è¶‹åŠ¿åˆ¤æ–­ï¼šè‹¥ä¸ºä¸Šå‡è¶‹åŠ¿ï¼Œä¿æŒæœ€å¤§marginï¼Œå¦åˆ™ä½¿ç”¨åŠ¨æ€marginã€‘===
        final_margin = np.where(hmm_signal == 1, atr_margin_max, dynamic_margin)

        df["adjusted_margin"] = final_margin  # ä¿ç•™ç”¨äºåˆ†æï¼Œå…³é”®å­—ï¼šåŠ¨æ€ATRç³»æ•°

        # ===ã€exit_priceè®¡ç®—ã€‘å…³é”®å­—ï¼šæ­¢æŸä»·ã€Kalmanã€åŠ¨æ€å¹³ä»“===
        df.loc[df.exit_price.isna(), "exit_price"] = (
            df.Kalman.shift(1) - df.ATR.shift(1) * df.adjusted_margin
        )
        return df

    def _calc_profit(self, base_df):
        last_valid_idx = base_df.exit_price.last_valid_index()
        start_idx = (
            0 if last_valid_idx is None else max(0, last_valid_idx - self.window + 1)
        )

        surf_df = base_df.iloc[start_idx:].copy()
        idx = surf_df.Stop_profit.isna()

        # åˆ©ç”¨ tail(self.window) ä¸­æ‰€æœ‰ High ä»·æ ¼è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆä¸å±€é™äºç¼ºå¤±è¡Œ, ä½†ç»“æœä¸€è‡´ï¼‰
        prices = surf_df.High.values.tolist()
        mean_price = statistics.mean(prices)
        stdv_price = statistics.stdev(prices)
        surfing_profit = mean_price + self.params.surfing_level * stdv_price

        surf_df.loc[surf_df.Stop_profit.isna(), "Stop_profit"] = surfing_profit
        # surf_df.loc[surf_df.exit_price.isna(), "exit_price"] = (
        #     surf_df.Kalman.shift(1) - surf_df.ATR.shift(1) * self.params.atr_loss_margin
        # )
        surf_df = self.adjust_exit_price_by_slope(surf_df)
        base_df.update(surf_df)

        # ç¬¬äºŒéƒ¨åˆ†ï¼šé‡ç®—ä¹°å–ä¿¡å·ä¸åˆ©æ¶¦æŒ‡æ ‡
        # å®šä½é‡æ–°è®¡ç®—çš„èµ·å§‹ç‚¹, åˆ©ç”¨ sell åˆ—ç¼ºå¤±çš„ç¬¬ä¸€ä¸ªç´¢å¼•
        resume_idx = base_df.sell.isna().idxmax()
        calc_df = base_df.loc[resume_idx:].copy()

        # ä¹°å…¥ä¿¡å·ï¼šå¯¹ buy ç¼ºå¤±è¡Œ, èµ‹å€¼ Close å¹¶è°ƒç”¨è‡ªå®šä¹‰ä¹°å…¥ä¿¡å·å‡½æ•°
        s_buy = calc_df.buy.isna()
        calc_df.loc[s_buy, "buy"] = calc_df.Close
        calc_df.loc[s_buy, "BuySignal"] = self.buy_signal_func(calc_df, self.params)

        # å–å‡ºä¿¡å·ï¼šæ»¡è¶³å·²æœ‰ä¹°å…¥ä¿¡å·ä¸”å½“æ—¥ Low å°äº exit_price çš„æƒ…å†µ
        s_sell = calc_df.buy.notna() & (calc_df.Kalman < calc_df.exit_price)
        # s_sell = calc_df.buy.notna() & (calc_df.HMM_State == 0)  # FIXME
        calc_df.loc[s_sell, "sell"] = calc_df.exit_price
        calc_df.loc[s_sell, "Matured"] = pd.to_datetime(calc_df.Date)

        # å‘åå¡«å…… sell ä¸ Matured, ç¡®ä¿ç©ºç¼ºéƒ¨åˆ†å¾—åˆ°å»¶ä¼¸
        calc_df.sell.bfill(inplace=True)
        calc_df.Matured.bfill(inplace=True)

        # åˆ©æ¶¦è®¡ç®—ï¼šä»…å¯¹ä¹°å…¥ä¸å–å‡ºå‡å­˜åœ¨ä¸” profit ç¼ºå¤±çš„è¡Œè®¡ç®—
        s_profit = calc_df.buy.notna() & calc_df.sell.notna() & calc_df.profit.isna()
        calc_df.loc[s_profit, "profit"] = (calc_df.sell / calc_df.buy) - 1
        calc_df.loc[s_profit, "P/L"] = (calc_df.sell - calc_df.buy) / (
            calc_df.ATR * self.params.atr_loss_margin
        )
        calc_df.loc[s_profit, "time_cost"] = [
            int(
                delta.seconds
                / 60
                / pandas_util.INTERVAL_TO_MIN.get(self.params.interval)
            )
            for delta in (
                pd.to_datetime(calc_df.loc[s_profit, "Matured"])
                - pd.to_datetime(calc_df.loc[s_profit, "Date"])
            )
        ]

        # è‹¥ buy ä¸ºç¼ºå¤±, åˆ™æ¸…ç©ºå¯¹åº”çš„ sell å’Œ Matured
        calc_df.loc[calc_df.buy.isna(), ["sell", "Matured"]] = [np.nan, pd.NaT]

        base_df.update(calc_df)
        return base_df

    def _calc_ATR(self, base_df):
        ATR_sample = self.params.ATR_sample
        upper_sample = self.params.upper_sample
        lower_sample = self.params.lower_sample

        last_valid_idx = base_df.ATR.last_valid_index()
        start_idx = (
            0 if last_valid_idx is None else max(0, last_valid_idx - self.window + 1)
        )

        df = base_df.iloc[start_idx:].copy()
        idx = df.ATR.isna()
        df.loc[idx, "Count_Hz"] = pandas_util.to_hz(self.params.interval, df.Count)
        df.loc[idx, "turtle_h"] = df.High.shift(1).rolling(upper_sample).max()
        df.loc[idx, "turtle_l"] = df.Low.shift(1).rolling(lower_sample).min()
        df.loc[idx, "h_l"] = df.High - df.Low
        df.loc[idx, "c_h"] = (df.Close.shift(1) - df.High).abs()
        df.loc[idx, "c_l"] = (df.Close.shift(1) - df.Low).abs()
        df.loc[idx, "TR"] = df[["h_l", "c_h", "c_l"]].max(axis=1)
        df.loc[idx, "ATR"] = df["TR"].rolling(ATR_sample).mean()
        df.loc[idx, "ATR_STDV"] = df["TR"].rolling(ATR_sample).std()

        df.loc[idx, "cv"] = np.log(df.TR * df.Vol)
        df.loc[idx, "cv_sum"] = df.cv.rolling(window=ATR_sample).sum()

        base_df.update(df)
        return base_df

    def _calc_OBV(self, base_df, multiplier=3.4):
        window = self.params.upper_sample
        df = base_df.copy()

        # Calculate price difference and direction
        df["price_diff"] = df["Close"].diff()
        df["direction"] = df["price_diff"].apply(
            lambda x: 1 if x > 0 else -1 if x < 0 else 0
        )
        df["Vol"] *= df["direction"]

        # Calculate OBV
        df["OBV"] = df["Vol"].cumsum()

        # Calculate moving average and standard deviation for OBV
        df["OBV_MA"] = df["OBV"].rolling(window=window).mean()
        df["OBV_std"] = df["OBV"].rolling(window=window).std()

        # Calculate upper and lower bounds
        df["upper_bound"] = df["OBV_MA"] + (multiplier * df["OBV_std"])
        df["lower_bound"] = df["OBV_MA"] - (multiplier * df["OBV_std"])

        # Calculate relative difference between bounds
        df["bound_diff"] = (df["upper_bound"] - df["lower_bound"]) / df["OBV_MA"]

        df["PRICE_UP"] = df["High"] >= (
            df["Close"].rolling(window=self.params.upper_sample).mean()
            + multiplier * df["Close"].rolling(window=self.params.upper_sample).std()
        )
        df["PRICE_LOW"] = df["Low"] <= (
            df["Close"].rolling(window=self.params.lower_sample).mean()
            + multiplier * df["Close"].rolling(window=self.params.lower_sample).std()
        )

        # è®¡ç®—æ»šåŠ¨çª—å£å†…çš„æ ‡å‡†å·®
        df["Rolling_Std"] = df["Close"].rolling(window=self.params.upper_sample).std()
        df["Rolling_Std_Percent"] = (
            df["Rolling_Std"]
            / df["Close"].rolling(window=self.params.upper_sample).mean()
        ) * 100

        # Identify significant points where OBV crosses the upper bound
        df["OBV_UP"] = (
            (df["OBV"] > df["upper_bound"])
            & (df["OBV"].shift(1) <= df["upper_bound"])
            # & (df["bound_diff"] > 0.07)
        )
        # print(df["bound_diff"])

        # Combine the new 'OBV_UP' column back to the original dataframe
        base_df["OBV"] = df["OBV"]
        base_df["OBV_MA"] = df["OBV_MA"]
        # base_df["OBV_UP"] = df["OBV_UP"] & (df["Slope"] >= 0)
        # base_df["OBV_UP"] = df["OBV_UP"] & df["PRICE_UP"]
        base_df["OBV_UP"] = df["OBV_UP"] & df["PRICE_LOW"]
        # base_df["OBV_UP"] = df["OBV_UP"]
        # base_df.at[df.index[-1], "OBV_UP"] = (
        #     df["Rolling_Std_Percent"].iloc[-1]
        #     <= df["Rolling_Std_Percent"]
        #     .rolling(window=self.params.bayes_windows)
        #     .min()
        #     .iloc[-1]
        # )

        base_df["Rolling_Std"] = df["Rolling_Std_Percent"]
        base_df["upper_bound"] = df["upper_bound"]
        base_df["lower_bound"] = df["lower_bound"]
        return base_df

    def calc_bocpd(self, df):
        if not self.bocpd_wrapper:
            # --- init once ---
            g0 = BOCPDGaussianG0(hazard=0.01, r_max=300)
            p1 = BOCPDStudentTP1(hazard=0.01, r_max=300)

            dual = DualBOCPD(g0, p1)
            cfg = PhaseFSMConfig()
            phase_fsm = BOCPDPhaseFSM(cfg)
            phase_fsm.warmup_ticks = 400

            self.bocpd_wrapper = DualBOCPDWrapper(
                dual_bocpd=dual,
                phase_fsm=phase_fsm,
                x_col="m_z_mix",
            )
            self.bocpd_wrapper.run_online(df)
        else:
            self.bocpd_wrapper.update_df_row(df, df.index[-1])
        return df

    def market_recon(self, base_df):
        base_df = pandas_util.equip_fields(base_df, TURTLE_COLUMNS)
        buy_signal_from_mosaic_strategy(base_df, self.params)
        base_df = self._calc_ATR(base_df)
        base_df = self._calc_OBV(base_df)
        base_df = calc_ADX(base_df, self.params, p=5)  # p=self.params.ATR_sample)
        base_df = self.calc_kalman(base_df)
        base_df = self.calc_bocpd(base_df)
        base_df = self.predict_hmm(base_df)
        base_df = self._calc_profit(base_df)
        # HACK remove me
        print(compare_signal_filters(base_df))
        print(analyze_hmm_states(base_df))
        return base_df

    def _simple_turtle_strategy(self, df, params):
        """
        Default simple turtle strategy to generate BuySignal.
        """
        return df.High > df.turtle_h


def emv_cross_strategy(df, params, short_windows=5, long_windws=60):
    idx = df.ema_short.isna()
    df.loc[idx, "ema_short"] = df.Close.ewm(span=short_windows, adjust=False).mean()
    df.loc[idx, "ema_long"] = df.Close.ewm(span=long_windws, adjust=False).mean()
    return (df.Kalman > df.ema_short) & (df.ema_short > df.ema_long)
    # return (df.iloc[-1].ema_short > df.iloc[-1].ema_long) & (
    #     df.iloc[-1].Kalman > df.iloc[-1].ema_short
    # )


def buy_signal_from_mosaic_strategy(df, params, short_windows=5, long_windws=60):
    """
    BuySignal = çµæ§‹ä½ç½® + åŠ›å­¸è½‰æŠ˜ï¼ˆthreshold éš¨ regime èª¿æ•´ï¼‰
    å‡è¨­ HMM å·²åœ¨å¤–å±¤ gate é
    """

    # === EMAï¼ˆä¿ç•™ï¼Œé›–ç„¶ç›®å‰æ²’ç›´æ¥ç”¨åœ¨ scoreï¼‰===
    idx = df.ema_short.isna()
    df.loc[idx, "ema_short"] = df.Close.ewm(span=short_windows, adjust=False).mean()
    df.loc[idx, "ema_long"] = df.Close.ewm(span=long_windws, adjust=False).mean()

    # === çµæ§‹æ¢ä»¶ ===
    cond_structure = df.c_z_center < -1.0

    # === åŠ›å­¸æ¢ä»¶ ===
    cond_force_pos = df.m_force_trend > 0
    cond_force_stable = df.m_force_trend.rolling(20).quantile(0.3) > 0

    # === ä¸–ç•Œç‹€æ…‹ï¼ˆregime noiseï¼‰===
    regime_noise = df.m_regime_noise_level
    regime_mean = regime_noise.rolling(20).mean()

    # === regime åˆ†æ®µï¼ˆä½ / ä¸­ / é«˜å™ªéŸ³ï¼‰===
    low_noise = regime_noise < regime_mean * 0.9
    mid_noise = (regime_noise >= regime_mean * 0.9) & (
        regime_noise <= regime_mean * 1.1
    )
    high_noise = regime_noise > regime_mean * 1.1

    # === Buy scoreï¼ˆä½ åŸæœ¬çš„è¨­è¨ˆï¼Œä¿ç•™ï¼‰===
    buy_score = 1.25 * cond_force_pos + 1.25 * cond_force_stable
    # buy_score = 1.0 * cond_structure + 0.5 * cond_force_pos + 0.5 * cond_force_stable

    # === Regime-adaptive threshold ===
    threshold = (
        1.0 * low_noise  # ä¸–ç•Œä¹¾æ·¨ï¼šä¸€å€‹å¼·ç†ç”±å°±å¯ä»¥
        + 1.5 * mid_noise  # ä¸–ç•Œæ™®é€šï¼šè‡³å°‘ 1.5 åˆ†
        + 2.0 * high_noise  # ä¸–ç•Œæ··äº‚ï¼šå¹¾ä¹è¦å…¨å°
    )

    return buy_score >= threshold


def calc_ADX(df, params, p=14):
    df = df.assign(
        **{
            "+DM": (df.High.diff().where(lambda x: x > -df.Low.diff()))
            .clip(0)
            .fillna(0),
            "-DM": (-df.Low.diff().where(lambda x: x > df.High.diff()))
            .clip(0)
            .fillna(0),
        }
    )
    df["+DM"] = df["+DM"].ewm(alpha=1 / p, adjust=False).mean()
    df["-DM"] = df["-DM"].ewm(alpha=1 / p, adjust=False).mean()
    df["+DI"] = (df["+DM"] / df.ATR).fillna(0)
    df["-DI"] = (df["-DM"] / df.ATR).fillna(0)
    df["DX"] = (abs(df["+DI"] - df["-DI"]) / (df["+DI"] + df["-DI"])).replace(np.inf, 0)
    df["ADX"] = df.DX.ewm(alpha=1 / p, adjust=False).mean()
    df["ADX_Signed"] = df["ADX"] * np.sign(df["+DI"] - df["-DI"])
    return df


import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from hmmlearn.hmm import GaussianHMM


def debug_hmm(hmm_model, hidden_states, df, X):
    """
    è¦–è¦ºåŒ– Hidden Markov Model (HMM) çš„å­¸ç¿’çµæœ, åŒ…å«ï¼š
    1. éš±è—ç‹€æ…‹æ™‚åºåœ–
    2. éš±è—ç‹€æ…‹é«˜æ–¯åˆ†ä½ˆ
    3. ç‹€æ…‹è½‰ç§»çŸ©é™£
    4. æ¨¡å‹å°æ•¸ä¼¼ç„¶å€¼
    5. æœªä¾†ç‹€æ…‹æ¨¡æ“¬

    åƒæ•¸ï¼š
    - hmm_model: è¨“ç·´å¥½çš„ GaussianHMM æ¨¡å‹
    - df: åŒ…å«è§€æ¸¬æ•¸æ“šçš„ DataFrame
    - feature_col: è§€æ¸¬æ•¸æ“šçš„æ¬„ä½åç¨± (é è¨­ç‚º "returns")
    - future_days: æ¨¡æ“¬æœªä¾†ç‹€æ…‹çš„å¤©æ•¸ (é è¨­ç‚º 10)
    """

    ## 1ï¸âƒ£ éš±è—ç‹€æ…‹æ™‚åºåœ–
    plt.figure(figsize=(12, 5))
    ax1 = plt.gca()
    ax2 = ax1.twinx()
    ax2.plot(df.index, df.Close, label="BTC Price", color="black", linewidth=1.5)
    ax2.plot(df.index, df.Kalman, label="Kalman Filter", color="blue", linewidth=1.5)
    ax2.legend(loc="upper right")
    ax1.set_ylabel("Features")
    ax2.set_ylabel("BTC Price")
    for i in range(hmm_model.n_components):
        ax1.fill_between(
            df.index,
            X[:, 0],
            where=(hidden_states == i),
            alpha=0.3,
            label=f"State {i} - KReturnVol",
        )
    for i in range(hmm_model.n_components):
        ax1.fill_between(
            df.index,
            X[:, 1],
            where=(hidden_states == i),
            alpha=0.3,
            label=f"State {i} - RVolume",
        )
    for i in range(hmm_model.n_components):
        ax1.fill_between(
            df.index,
            X[:, 2],
            where=(hidden_states == i),
            alpha=0.3,
            label=f"State {i} - Slope",
        )
    ax1.legend()
    plt.title("Hidden States Over Time")
    plt.xlabel("Date")
    plt.ylabel("feature_col")
    plt.show()
    ## 2ï¸âƒ£ éš±è—ç‹€æ…‹çš„é«˜æ–¯åˆ†ä½ˆ
    means = hmm_model.means_.flatten()
    covars = np.sqrt(hmm_model.covars_.flatten())

    plt.figure(figsize=(8, 5))
    for i in range(hmm_model.n_components):
        sns.kdeplot(X[hidden_states == i].ravel(), label=f"State {i}", shade=True)
    plt.axvline(
        means[0], color="blue", linestyle="--", label=f"Mean State 0: {means[0]:.2f}"
    )
    plt.axvline(
        means[1], color="red", linestyle="--", label=f"Mean State 1: {means[1]:.2f}"
    )
    plt.legend()
    plt.title("Gaussian Distributions of Hidden States")
    plt.xlabel("feature_col")
    plt.show()

    ## 3ï¸âƒ£ ç‹€æ…‹è½‰ç§»çŸ©é™£ï¼ˆç†±åŠ›åœ–ï¼‰
    trans_mat = hmm_model.transmat_

    plt.figure(figsize=(6, 5))
    sns.heatmap(
        trans_mat,
        annot=True,
        cmap="coolwarm",
        fmt=".2f",
        xticklabels=[f"State {i}" for i in range(hmm_model.n_components)],
        yticklabels=[f"State {i}" for i in range(hmm_model.n_components)],
    )
    plt.title("HMM State Transition Matrix")
    plt.xlabel("Next State")
    plt.ylabel("Current State")
    plt.show()

    ## 4ï¸âƒ£ æ‰“å°æ¨¡å‹å°æ•¸ä¼¼ç„¶å€¼
    log_likelihood = hmm_model.score(X)
    print(f"\nğŸ” Log-Likelihood of the trained HMM: {log_likelihood:.2f}")

    print("\nâœ… HMM Debug å®Œæˆï¼è«‹æª¢æŸ¥ä¸Šé¢çš„åœ–è¡¨ä¾†åˆ†æ HMM æ˜¯å¦åˆç†åœ°åŠƒåˆ†äº†å¸‚å ´ç‹€æ…‹ã€‚")


def hmm_standardize(series: pd.Series, window: int = 20) -> pd.DataFrame:
    _log = np.log(series + ZERO)
    _ma = series.rolling(window).mean()
    _relative_strength = series / _ma
    _zscore = (series - _ma) / series.rolling(window).std()
    # _sortino = sortino_ratio(series)
    return _log, _ma, _relative_strength, _zscore


def sortino_ratio(series, rf=0.0):
    downside = series[series < rf]
    downside_std = downside.std(ddof=0)
    if np.isnan(downside_std):
        downside_std = ZERO
    return (series.mean() - rf) / downside_std


def hmm_performance(df: pd.DataFrame, min_count: int = 300) -> int:
    """
    åŸç†ï¼ˆç›´è¦ºç‰ˆï¼‰ï¼š
    1) HMM æ¯å€‹ state ä»£è¡¨ä¸€ç¨®ã€Œå¸‚å ´ç‹€æ…‹ã€ï¼›æˆ‘å€‘ä¸æƒ³è¢«æ¨£æœ¬å¤ªå°‘çš„ state é¨™ã€‚
    2) å…ˆç”¨ state çš„å‡ºç¾æ¬¡æ•¸éæ¿¾æ‰ã€Œå†·é–€/ä¸å¯é ã€ç‹€æ…‹ï¼ˆcount >= min_countï¼‰ã€‚
    3) å°æ¯å€‹å¯é  state å–ç‰¹å¾µå‡å€¼ï¼Œè·Ÿã€Œç†æƒ³çš„æ ¸å¿ƒè¶¨å‹¢ç‹€æ…‹ã€åšè·é›¢æ¯”è¼ƒï¼š
       - consensus_norm è¶Šé«˜è¶Šå¥½ï¼ˆ+1ï¼‰
       - trend_norm è¶Šé«˜è¶Šå¥½ï¼ˆ+1ï¼‰
       - TR_norm è¶Šæ¥è¿‘ 0 è¶Šå¥½ï¼ˆ0ï¼Œä»£è¡¨ä¸éç†±ä¸éå†·ï¼‰
       - bias_off_norm è¶Šä½è¶Šå¥½ï¼ˆ-1ï¼‰
    4) è·é›¢è¶Šå°è¶Šåƒæ ¸å¿ƒè¶¨å‹¢ç‹€æ…‹ï¼›å›å‚³è©² state idã€‚
    """
    df = df.copy()

    counts = df["HMM_State"].value_counts()
    valid_states = counts[counts >= min_count].index

    prof = (
        df.groupby("HMM_State")[["RCS", "trend_norm", "TR_norm", "bias_off_norm"]]
        .mean()
        .loc[valid_states]
    )

    ideal = pd.Series(
        {
            "RCS": +1.0,
            "trend_norm": +1.0,
            "TR_norm": 0.0,
            "bias_off_norm": -1.0,
        }
    )

    prof["score"] = (prof.sub(ideal) ** 2).sum(axis=1)
    print(prof)
    return int(prof["score"].idxmin())


# def hmm_performance(df: pd.DataFrame):
#     df = df.copy()
#     df["log_return"] = np.log(df.Close / df.Close.shift(1))
#     df.dropna(subset=["log_return", "HMM_State"], inplace=True)
#     result = (
#         df.groupby("HMM_State")
#         .agg(
#             avg_return=("log_return", "mean"),
#             std_return=("log_return", "std"),
#             count=("log_return", "count"),
#             sortino_ratio=("log_return", sortino_ratio),
#         )
#         .reset_index()
#     )

#     return result.sortino_ratio.idxmax()


# def hmm_performance(df: pd.DataFrame):
#     df = df.copy()

#     # è¨ˆç®— log return
#     df["log_return"] = np.log(df.Close / df.Close.shift(1))

#     # ç§»é™¤ NaN
#     df.dropna(subset=["log_return", "HMM_State"], inplace=True)

#     # å»ºç«‹è¼¸å‡ºè¡¨æ ¼
#     result = (
#         df.groupby("HMM_State")
#         .agg(
#             avg_return=("log_return", "mean"),
#             std_return=("log_return", "std"),
#             count=("log_return", "count"),
#             sortino_ratio=("log_return", sortino_ratio),
#         )
#         .reset_index()
#     )

#     # è¨ˆç®—å¹³å‡æŒçºŒæ™‚é–“ï¼ˆæ¯æ®µé€£çºŒå‡ºç¾ç‹€æ…‹çš„é•·åº¦ï¼‰
#     durations = []
#     prev_state = None
#     count_duration = 0
#     for state in df["HMM_State"]:
#         if state == prev_state:
#             count_duration += 1
#         else:
#             if prev_state is not None:
#                 durations.append((prev_state, count_duration))
#             prev_state = state
#             count_duration = 1
#     if prev_state is not None:
#         durations.append((prev_state, count_duration))

#     duration_df = pd.DataFrame(durations, columns=["state", "duration"])
#     avg_durations = (
#         duration_df.groupby("state")["duration"]
#         .mean()
#         .reset_index()
#         .rename(columns={"state": "HMM_State", "duration": "avg_duration"})
#     )

#     # åˆä½µå…©å¼µè¡¨
#     result = result.merge(avg_durations, on="HMM_State", how="left")

#     # åŠ å…¥ weighted score è¨ˆç®—ï¼ˆæ­£è¦åŒ–æ–¹å¼ï¼‰
#     result["weight_count_std"] = (result["count"] / result["std_return"]).rank(pct=True)
#     result["weight_duration"] = np.sqrt(result["avg_duration"]).rank(pct=True)
#     result["weighted_score"] = result["sortino_ratio"] * (
#         0.6 * result["weight_count_std"] + 0.4 * result["weight_duration"]
#     )
#     return result


from quanthunt.utils import pandas_util
from quanthunt.hunterverse.interface import IStrategyScout
from quanthunt.hunterverse.interface import IMarketSensor
from quanthunt.hunterverse.interface import IEngine
from quanthunt.hunterverse.interface import IHunter
from quanthunt.hunterverse.interface import Symbol
from quanthunt.hunterverse.interface import StrategyParam
from quanthunt.hunterverse.interface import INTERVAL_TO_MIN
from quanthunt.hunterverse.interface import xBuyOrder, xSellOrder
from quanthunt.hunterverse.interface import DEBUG_COL, DUMP_COL
from quanthunt.sensor.market_sensor import HuobiMarketSensor
from quanthunt.config.core_config import config

DATA_DIR, SRC_DIR, REPORTS_DIR = config.data_dir, config.src_dir, config.reports_dir

if __name__ == "__main__":
    import click

    @click.command()
    @click.option("--symbol", default="moveusdt", help="Trading symbol (e.g. trxusdt)")
    @click.option("--interval", default="1min", help="Trading interval")
    @click.option("--count", default=2000, help="load datas")
    @click.option("--hmm_split", default=5, type=int, help="hmm status split")
    def main(symbol: str, interval: str, count: int, hmm_split: int):
        params = {
            "ATR_sample": 60,
            "bayes_windows": 20,
            "lower_sample": 60,
            "upper_sample": 60,
            "hard_cutoff": 0.9,
            "profit_loss_ratio": 3,
            "atr_loss_margin": 1.5,
            "surfing_level": 5,
            "interval": interval,
            "funds": 50,
            "stake_cap": 10,
            "symbol": Symbol(symbol),
            "hmm_split": hmm_split,
            "backtest": True,
            "debug_mode": ["statement"],
            "api_key": os.getenv("API_KEY"),
            "secret_key": os.getenv("SECRET_KEY"),
        }
        sp = StrategyParam(**params)

        sensor = HuobiMarketSensor(symbol=sp.symbol, interval=sp.interval)
        base_df = sensor.scan(count)
        # cut = pd.Timestamp("2025-06-04 15:00:00")
        # base_df = base_df[base_df["Date"] >= cut].reset_index()

        scout = TurtleScout(params=sp, buy_signal_func=buy_signal_from_mosaic_strategy)
        scout = TurtleScout(sp)
        base_df = scout.train(base_df)
        base_df = scout.market_recon(base_df)
        report_cols = DUMP_COL

        base_df[report_cols].to_csv(f"{REPORTS_DIR}/{sp}_hmm_test.csv", index=False)
        print(f"created: {REPORTS_DIR}/{sp}_hmm_test.csv")
        hmm_table = hmm_performance(base_df)
        # print(hmm_table)
        print(
            f"BEST HMM_STATE: {hmm_table.loc[hmm_table['weighted_score'].idxmax(), 'HMM_State']}"
        )
        return base_df[report_cols]

    main()
